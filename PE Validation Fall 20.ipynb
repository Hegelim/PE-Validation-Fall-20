{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PE Validation Fall 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules \n",
    "# please run this everytime you open it\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib as plt \n",
    "import seaborn as sns\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out a way to read in schema txt files (inside the schema folder)\n",
    "# for example, I have a source file (such as Source_relevance.csv) and \n",
    "# I know the question_label, but I want to build a function to know \n",
    "# whether this question (Q1/Q2..) is multiple-choice or checklist\n",
    "# build a function to accomplish this\n",
    "# func(schemafile(...txt), input(..csv), question_label(Q1/Q2...)) -> checlist/multiple choice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not only do I want to know whether it's multiple-choice or checklist \n",
    "# I also want to know how many different answer choices are there\n",
    "# build a function to accomplish this \n",
    "# func(schemafile(...txt), input(..csv), question_label(Q1/Q2...)) -> # of different answer choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out how to uniquely identify each submission, \n",
    "# since there might be one contributor who made \n",
    "# several submissions. \n",
    "# can't use contributor_uuid. What to use? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encode checklist questions to [0, 1]\n",
    "# for example, Q4 in source relevance task is a checklist question\n",
    "# if someone selects both A1 and A2, then it's [1, 1]\n",
    "# return a dataframe that has each question_label but list out the answers in [] format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation ground below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charlie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Katherine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yewen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read json lines file \n",
    "# data = pd.read_json('2020 data/2020-09-25_pe_webhooks.jsonl', lines=True)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source[source[\"contributor_uuid\"] == \"00f548b7-6b63-4b47-828e-8e416b6ca0e2\"][[\"contributor_uuid\", \"created\", \"finish_time\", \"elapsed_seconds\", \"question_label\", \"answer_label\", \"answer_uuid\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triager to uAlpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping for topic_name\n",
    "dic = {\"Quoted Sources\":1,\n",
    "           \"Arguments\":2,\n",
    "           \"Assertions\":3, \n",
    "           \"Needs Fact-Check\":4, \n",
    "           \"Language\":5, \n",
    "           \"Reasoning\":6, \n",
    "           \"Probability\":7, \n",
    "           \"Evidence\":8}\n",
    "\n",
    "    \n",
    "# mapping topic_name to integers \n",
    "def mapping(df, dic):\n",
    "    # df - dataframe to be mapped \n",
    "    # dic - dictionary of mapping \n",
    "    df[\"topic_name\"] = df[\"topic_name\"].map(dic)\n",
    "    return df \n",
    "\n",
    "# add adjusted start_pos and adjusted end_pos for df \n",
    "def adjust(df):\n",
    "    # df - a dataframe with [\"article_number\", \"article_text_length\", \"start_pos\", \"end_pos\"] cols\n",
    "    article_number = df[\"article_number\"]\n",
    "    article_text_length = df[\"article_text_length\"]\n",
    "    start_pos = df[\"start_pos\"]\n",
    "    end_pos = df[\"end_pos\"]\n",
    "    # the cumulative sum of article_text_length\n",
    "    cumulative = []\n",
    "    start_pos_adjusted = []\n",
    "    end_pos_adjusted = []\n",
    "    pre_total = 0\n",
    "    total = article_text_length[0]\n",
    "    cur_num = article_number[0]\n",
    "    for i in np.arange(len(article_number)):\n",
    "        if article_number[i] == cur_num:\n",
    "            total = total + 0\n",
    "            cumulative.append(total)\n",
    "        else:\n",
    "            pre_total = total\n",
    "            cur_num = article_number[i]\n",
    "            total = total + article_text_length[i]\n",
    "            cumulative.append(total)\n",
    "        start_pos_adjusted.append(start_pos[i] + pre_total)\n",
    "        end_pos_adjusted.append(end_pos[i] + pre_total)\n",
    "    df[\"cumulative\"] = cumulative\n",
    "    df[\"start_pos_adjusted\"] = start_pos_adjusted\n",
    "    df[\"end_pos_adjusted\"] = end_pos_adjusted\n",
    "    return df \n",
    "\n",
    "\n",
    "# filter df and select only certain cols as input\n",
    "def slice_input(df):\n",
    "    cols = [\"contributor_uuid\", \"topic_name\", \"start_pos\",\n",
    "            \"end_pos\", \"article_text_length\", \"article_number\"]\n",
    "    return df.reindex(columns=cols)\n",
    "\n",
    "\n",
    "# filter df and select only certain cols as output\n",
    "def slice_output(df):\n",
    "    cols = [\"contributor_uuid\", \"topic_name\", \"blank\",  \n",
    "            \"start_pos_adjusted\", \"end_pos_adjusted\"]\n",
    "    return df.reindex(columns=cols)\n",
    "    \n",
    "\n",
    "# read in a directory that contains Triager csvs \n",
    "# split each Triager csv to 4 other csvs based on topic_name (argument, reasoning, etc)\n",
    "# and write it as csvs in the output directory\n",
    "def triager_split(input_directory, output_directory):\n",
    "    # input_directory - e.g. \"Triager data\"\n",
    "    # output_directory - e.g. \"Triager output\"\n",
    "    for file in os.listdir(input_directory):\n",
    "        triager_split_help(input_directory, file, output_directory)\n",
    "    print(\"Triager Tranformation Done! Ready to be imported to uAlpha!\")\n",
    "    \n",
    "# take in a Triager csv and split it to 4 different csvs \n",
    "# based on topic_name \n",
    "def triager_split_help(input_directory, fileName, output_directory):\n",
    "    # input_directory - e.g. \"Triager data\"\n",
    "    # fileName - e.g. \"Covid_Form1.0.adjudicated-2020-10-04T2314-Tags.csv\"\n",
    "    # output_directory - e.g. \"Triager output\"\n",
    "    name = os.path.join(input_directory, fileName)\n",
    "    df = pd.read_csv(name)\n",
    "    # different topic_names \n",
    "    topic_names = df[\"topic_name\"].unique()\n",
    "    for topic in topic_names: \n",
    "        # select all rows for that specific topic name \n",
    "        df_topic = df.loc[df[\"topic_name\"] == topic]\n",
    "        # re-index such that its index starts from 0 again\n",
    "        df_topic.reset_index(drop=True, inplace=True)\n",
    "        # select only these columns \n",
    "        filtered = slice_input(df_topic)\n",
    "        # slice contributor_uuid with the first 6 chars \n",
    "        filtered[\"contributor_uuid\"] = filtered[\"contributor_uuid\"].str[:6]\n",
    "        # map topic_name to integers\n",
    "        mapping(filtered, dic)\n",
    "        # add one column of u + str(row) and set it as index \n",
    "        index = 'u' + pd.Series(filtered.index).astype(str)\n",
    "        filtered.set_index(keys=index, inplace=True)\n",
    "        # add a blank column \n",
    "        filtered.insert(loc=3, column=\"blank\", value=\"\")\n",
    "        # add modified columns\n",
    "        filtered = adjust(filtered)\n",
    "        # filter and select only certain columns \n",
    "        output = slice_output(filtered)\n",
    "        # the batch_name, e.g. \"Covid\"\n",
    "        batch_name = re.split(r'_', fileName)[0]\n",
    "        name = '{0}-Triager-{1}.csv'.format(batch_name, topic)\n",
    "        path = os.path.join(output_directory, name)\n",
    "        # write to csvs\n",
    "        output.to_csv(path, header=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triager Tranformation Done! Ready to be imported to uAlpha!\n"
     ]
    }
   ],
   "source": [
    "triager_split(\"Triager data\", \"Triager output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging function - find potential overlapping issue \n",
    "def detect_overlapping(input_directory, fileName):\n",
    "    # input directory - e.g. \"Triager output\"\n",
    "    # fileName - e.g. \"Covid-Triager-Arguments.csv\"\n",
    "    name = os.path.join(input_directory, fileName)\n",
    "    df = pd.read_csv(name, header=None)\n",
    "    # all the unique user \n",
    "    users = df.iloc[:, 1].unique()\n",
    "    # iterate through all unique user \n",
    "    for user in users:\n",
    "        # first only select the rows of that user \n",
    "        # use copy to deal with the wanring\n",
    "        piece = df.loc[df[1] == user].copy()\n",
    "        # sort the 4th column\n",
    "        piece.sort_values(by=4, inplace=True)\n",
    "        # find or not\n",
    "        found = False \n",
    "        start_pos = np.array(piece[4])\n",
    "        end_pos = np.array(piece[5])\n",
    "        for i in np.arange(1, len(start_pos)):\n",
    "            if start_pos[i] > end_pos[i-1]:\n",
    "                continue\n",
    "            else:\n",
    "                found = True\n",
    "                print('user {0}, start_pos {1}, end_pos {2} begin overlapping!'.format(user, start_pos[i], end_pos[i]))\n",
    "                break \n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user e08341, start_pos 6218, end_pos 6582 begin overlapping!\n",
      "user aac18e, start_pos 4536, end_pos 4552 begin overlapping!\n",
      "user e44f57, start_pos 18258, end_pos 18424 begin overlapping!\n"
     ]
    }
   ],
   "source": [
    "detect_overlapping(\"Triager output\", \"Covid-Triager-Arguments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>u101</td>\n",
       "      <td>e08341</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6173</td>\n",
       "      <td>6230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>u104</td>\n",
       "      <td>e08341</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6218</td>\n",
       "      <td>6582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>u102</td>\n",
       "      <td>e08341</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7199</td>\n",
       "      <td>7294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1  2   3     4     5\n",
       "11  u101  e08341  2 NaN  6173  6230\n",
       "12  u104  e08341  2 NaN  6218  6582\n",
       "13  u102  e08341  2 NaN  7199  7294"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = argument.loc[argument.iloc[:, 1] == \"e08341\", :].sort_values(by=4)\n",
    "a.reset_index(inplace=True, drop=True)\n",
    "a.iloc[11:14, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContribData(object):\n",
    "    def __init__(self):\n",
    "        self.flattened = set()\n",
    "        self.case_number_dict = {}\n",
    "\n",
    "    def consider(self, anno):\n",
    "        # Flatten all of a user's highlights for a given topic into\n",
    "        # a single set. Otherwise the user could increase the weight of\n",
    "        # their highlights by overlapping them.\n",
    "        anno_set = set(range(int(anno[4]), int(anno[5])))\n",
    "        self.flattened |= anno_set\n",
    "        # case numbers from a user must be disjoint.\n",
    "        # But front-end allows annotation overlaps.\n",
    "        # Keep the lowest case number assigned by this contributor.\n",
    "        case_number_keys = self.case_number_dict.keys()\n",
    "        new_keys = anno_set - case_number_keys\n",
    "        overlapped_keys = case_number_keys & anno_set\n",
    "        proposed = int(anno['case_number'])\n",
    "        new_dict = dict.fromkeys(new_keys, proposed)\n",
    "        overlapped_dict = {\n",
    "            k: min(self.case_number_dict[k], proposed)\n",
    "            for k in overlapped_keys\n",
    "        }\n",
    "        self.case_number_dict.update(new_dict)\n",
    "        self.case_number_dict.update(overlapped_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u9</td>\n",
       "      <td>e08341</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u10</td>\n",
       "      <td>e08341</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>262</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u11</td>\n",
       "      <td>e08341</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>758</td>\n",
       "      <td>879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u12</td>\n",
       "      <td>e08341</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>882</td>\n",
       "      <td>1512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u13</td>\n",
       "      <td>e08341</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1624</td>\n",
       "      <td>2436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0       1  2   3     4     5\n",
       "0   u9  e08341  2 NaN   113   259\n",
       "1  u10  e08341  2 NaN   262   370\n",
       "2  u11  e08341  2 NaN   758   879\n",
       "3  u12  e08341  2 NaN   882  1512\n",
       "4  u13  e08341  2 NaN  1624  2436"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
